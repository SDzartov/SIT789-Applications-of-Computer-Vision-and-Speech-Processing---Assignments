{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426c2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8b972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extraction(audio_filename, #.wav filename\n",
    "                    hop_duration, #hop_length in seconds, e.g., 0.015s (i.e., 15ms)\n",
    "                    num_mfcc #number of mfcc features\n",
    "                   ): \n",
    "    speech = AudioSegment.from_wav(audio_filename) #Read audio data from file\n",
    "    samples = speech.get_array_of_samples() #samples x(t)\n",
    "    sampling_rate = speech.frame_rate #sampling rate f\n",
    " \n",
    "    mfcc = librosa.feature.mfcc(np.float32(samples), \n",
    "                                sr = sampling_rate, \n",
    "                                hop_length = int(sampling_rate * hop_duration), \n",
    "                                n_mfcc = num_mfcc)\n",
    " \n",
    "    return mfcc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b83c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "def learningGMM(features, #list of feature vectors, each feature vector is an array\n",
    "                n_components, #the number of components\n",
    "                max_iter #maximum number of iterations\n",
    "               ):\n",
    "    gmm = GaussianMixture(n_components = n_components, max_iter = max_iter)\n",
    "    gmm.fit(features)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82debd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anthony', 'AppleEater', 'Ara', 'Argail', 'Ariyan', 'Arjuan', 'Artem', 'Arthur', 'Artk', 'Arun', 'Arvala', 'Asalkeld', 'Asladic', 'Asp', 'Azmisov', 'B', 'Bachroxx', 'Bae', 'Bahoke', 'Bareford', 'Bart', 'Bassel', 'Beady', 'Beez', 'BelmontGuy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'SpeakerData/'\n",
    "speakers = os.listdir(path + 'Train/')\n",
    "print(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c50a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this list is used to store the MFCC features of all training data of all speakers\n",
    "mfcc_all_speakers = [] \n",
    "hop_duration = 0.015 #15ms\n",
    "num_mfcc = 12\n",
    "for s in speakers:\n",
    "    sub_path = path + 'Train/' + s + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    mfcc_one_speaker = np.asarray(())\n",
    "    for fn in sub_file_names:\n",
    "        mfcc_one_file = mfcc_extraction(fn, hop_duration, num_mfcc)\n",
    "        if mfcc_one_speaker.size == 0:\n",
    "            mfcc_one_speaker = mfcc_one_file\n",
    "        else:\n",
    "            mfcc_one_speaker = np.vstack((mfcc_one_speaker, mfcc_one_file))\n",
    "    mfcc_all_speakers.append(mfcc_one_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cbc9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this list is used to store the MFCC features of all test data of all speakers\n",
    "test_mfcc_all_speakers = [] \n",
    "hop_duration = 0.015 #15ms\n",
    "num_mfcc = 12\n",
    "for s in speakers:\n",
    "    sub_path = path + 'Test/' + s + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    mfcc_one_speaker = np.asarray(())\n",
    "    for fn in sub_file_names:\n",
    "        mfcc_one_file = mfcc_extraction(fn, hop_duration, num_mfcc)\n",
    "        if mfcc_one_speaker.size == 0:\n",
    "            mfcc_one_speaker = mfcc_one_file\n",
    "        else:\n",
    "            mfcc_one_speaker = np.vstack((mfcc_one_speaker, mfcc_one_file))\n",
    "    test_mfcc_all_speakers.append(mfcc_one_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "940a9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for i in range(0, len(speakers)):\n",
    "    with open('TrainingFeatures/' + speakers[i] + '_mfcc.fea','wb') as f:\n",
    "        pickle.dump(mfcc_all_speakers[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6dcb311",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "max_iter = 50\n",
    "gmms = [] #list of GMMs, each is for a speaker\n",
    "for i in range(0, len(speakers)):\n",
    "    gmm = learningGMM(mfcc_all_speakers[i], \n",
    "                      n_components, \n",
    "                      max_iter)\n",
    "    gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ae6378e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(speakers)):\n",
    "    with open('Models/' + speakers[i] + '.gmm', 'wb') as f: #'wb' is for binary write\n",
    "        pickle.dump(gmms[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b331b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmms = []\n",
    "for i in range(len(speakers)):\n",
    "    with open('Models/' + speakers[i] + '.gmm', 'rb') as f: #'wb' is for binary write\n",
    "        gmm = pickle.load(f)\n",
    "        gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e457059",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cb17a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaker_recognition(audio_file_name, gmms):\n",
    "    spkers = []\n",
    "    item = mfcc_extraction(audio_file_name,hop_duration, num_mfcc)\n",
    "    for i in range(0,len(gmms)):\n",
    "        spkers.append(gmms[i].score(item))\n",
    "    index_max = np.argmax(spkers)\n",
    "    speaker_id = index_max\n",
    "    return speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62cb3f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ara\n"
     ]
    }
   ],
   "source": [
    "speaker_id = speaker_recognition('SpeakerData/Test/Ara/a0522.wav', gmms)\n",
    "print(speakers[speaker_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6f6e7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed48b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'SpeakerData/'\n",
    "test_file_names = []\n",
    "test_file_labels = []\n",
    "for i in range(0, len(speakers)):\n",
    "    sub_path = path + 'Test/' + speakers[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    sub_speaker_labels = [i] * len(sub_file_names)\n",
    "    test_file_names += sub_file_names\n",
    "    test_file_labels += sub_speaker_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "43fcc5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anthony', 'Anthony', 'Anthony', 'Anthony', 'Anthony', 'Anthony', 'Anthony', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'Ara', 'Ara', 'Ara', 'Ara', 'Ara', 'Ara', 'Ara', 'Argail', 'Argail', 'Argail', 'Argail', 'Argail', 'Argail', 'Argail', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Artem', 'Artem', 'Artem', 'Artem', 'Artem', 'Artem', 'Artem', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Artk', 'Artk', 'Artk', 'Artk', 'Artk', 'Artk', 'Artk', 'Arun', 'Arun', 'Arun', 'Arun', 'Arun', 'Arun', 'Arun', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asp', 'Asp', 'Asp', 'Asp', 'Asp', 'Asp', 'Asp', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bae', 'Bae', 'Bae', 'Bae', 'Bae', 'Bae', 'Bae', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bart', 'Bart', 'Bart', 'Bart', 'Bart', 'Bart', 'Bart', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Beady', 'Beady', 'Beady', 'Beady', 'Beady', 'Beady', 'Beady', 'Beez', 'Beez', 'Beez', 'Beez', 'Beez', 'Beez', 'Beez', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy']\n"
     ]
    }
   ],
   "source": [
    "truelabels = []\n",
    "for i in range(0,len(test_file_labels)):\n",
    "    speakerid = speakers[test_file_labels[i]]\n",
    "    truelabels.append(speakerid)\n",
    "print(truelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "562c1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anthony', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'AppleEater', 'Ara', 'Ara', 'Ara', 'Ara', 'Ara', 'Ara', 'Ara', 'Argail', 'Argail', 'Argail', 'Argail', 'Argail', 'Argail', 'Argail', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Ariyan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Arjuan', 'Artem', 'Artem', 'Artem', 'Artem', 'Artem', 'Artem', 'Artem', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Arthur', 'Artk', 'Artk', 'Artk', 'Artk', 'Artk', 'Artk', 'Artk', 'Arun', 'Arun', 'Arun', 'Arun', 'Arun', 'Arun', 'Arun', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Arvala', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asalkeld', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asladic', 'Asp', 'Asp', 'Asp', 'Asp', 'Asp', 'Asp', 'Asp', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'Azmisov', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bachroxx', 'Bae', 'Bae', 'Bae', 'Bae', 'Bae', 'Bae', 'Bae', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bahoke', 'Bassel', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bareford', 'Bart', 'Arthur', 'Arthur', 'Bart', 'Bart', 'Bart', 'Arthur', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Bassel', 'Beady', 'Beady', 'Beady', 'Beady', 'Beady', 'Beady', 'Beady', 'Beez', 'Beez', 'Beez', 'Beez', 'Beez', 'Beez', 'Beez', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy', 'BelmontGuy']\n"
     ]
    }
   ],
   "source": [
    "testmfccfeatures = []\n",
    "predictlab = []\n",
    "for i in range(0,len(test_file_names)):\n",
    "    speaker_id = speaker_recognition(test_file_names[i],gmms)\n",
    "    predict = speakers[speaker_id]\n",
    "    predictlab.append(predict)\n",
    "print(predictlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a655f0a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7]]\n",
      "94.28571428571428\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(truelabels,predictlab)\n",
    "acc = accuracy_score(truelabels,predictlab)\n",
    "print(cm)\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135fb0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
